Issue Type,Detection Method,Solution,Python Code,SQL Code,Impact
Missing Values,df.isnull().sum() and df.isnull().mean(),"Drop rows, impute with mean/median/mode, forward fill, or flag with indicator","df['col'].fillna(df['col'].median(), inplace=True) or df.dropna(subset=['required_col'])","COALESCE(column, 0) or WHERE column IS NOT NULL","Missing data can skew aggregations, break joins, and cause errors"
Duplicate Rows,df.duplicated().sum() and df[df.duplicated()],"Remove exact duplicates or dedupe by key keeping latest","df.drop_duplicates(subset=['id'], keep='last', inplace=True)","WITH ranked AS (SELECT *, ROW_NUMBER() OVER (PARTITION BY id ORDER BY updated_at DESC) as rn FROM table) SELECT * FROM ranked WHERE rn = 1","Duplicates inflate counts, sums, and cause join multiplication"
Outliers,df.describe() and boxplot IQR method,"Remove, cap/Winsorize, or investigate - depends on domain","Q1, Q3 = df['col'].quantile([0.25, 0.75]); IQR = Q3-Q1; df = df[(df['col'] >= Q1-1.5*IQR) & (df['col'] <= Q3+1.5*IQR)]","WHERE value BETWEEN (SELECT PERCENTILE_CONT(0.25) - 1.5*IQR) AND (SELECT PERCENTILE_CONT(0.75) + 1.5*IQR)","Outliers can dominate averages and distort visualizations"
Data Type Mismatch,df.dtypes and df['col'].apply(type).value_counts(),"Convert to correct type with error handling","df['date'] = pd.to_datetime(df['date'], errors='coerce'); df['amount'] = pd.to_numeric(df['amount'], errors='coerce')","CAST(column AS DATE) or TRY_CAST for safe conversion","Wrong types cause sorting, filtering, and aggregation errors"
Inconsistent Date Formats,df['date'].str.contains(pattern).value_counts(),"Standardize to ISO format YYYY-MM-DD","df['date'] = pd.to_datetime(df['date'], format='mixed').dt.strftime('%Y-%m-%d')","TO_DATE(date_string, 'format pattern')","Inconsistent dates cause parsing errors and incorrect sorting"
Leading/Trailing Whitespace,df['col'].str.len() vs df['col'].str.strip().str.len(),"Strip whitespace from string columns","df['col'] = df['col'].str.strip()","TRIM(column)","Whitespace causes join failures and lookup misses"
Case Inconsistency,df['col'].str.lower().nunique() vs df['col'].nunique(),"Standardize to lowercase or title case","df['col'] = df['col'].str.lower() or .str.title()","LOWER(column) or UPPER(column)","Case differences cause grouping errors and aggregation issues"
Invalid Categories,df['category'].isin(valid_list).value_counts(),"Map invalid values or flag/remove","df['category'] = df['category'].replace({'invalid': 'Unknown'}); df = df[df['category'].isin(valid_list)]","CASE WHEN category IN ('valid1', 'valid2') THEN category ELSE 'Other' END","Invalid categories skew analysis and break filters"
Negative Values Where Impossible,df[df['col'] < 0].count(),"Flag, remove, or convert to absolute value","df = df[df['quantity'] >= 0] or df['quantity'] = df['quantity'].abs()","WHERE quantity >= 0 or ABS(quantity)","Negative quantities/prices indicate data entry errors"
Future Dates in Historical Data,df[df['date'] > pd.Timestamp.today()],"Remove or flag future-dated records","df = df[df['date'] <= pd.Timestamp.today()]","WHERE date <= CURRENT_DATE","Future dates indicate data pipeline or entry errors"
Zero Division Risk,df[df['denominator'] == 0].count(),"Handle zeros before division with NULLIF or fillna","df['ratio'] = df['numerator'] / df['denominator'].replace(0, np.nan)","numerator / NULLIF(denominator, 0)","Division by zero causes errors or inf values"
Encoding Issues,df['col'].str.contains('[^\x00-\x7F]'),"Fix encoding or remove special characters","df['col'] = df['col'].str.encode('ascii', 'ignore').str.decode('ascii')","REGEXP_REPLACE(col, '[^[:ascii:]]', '')","Encoding issues cause display and processing errors"
Null vs Zero Ambiguity,df['col'].isin([0, None]).value_counts(),"Decide semantic meaning: is 0 different from null?","Document decision: df['col'] = df['col'].fillna(0) # if semantically equivalent","Add explicit flag: CASE WHEN col IS NULL THEN 'Unknown' ELSE 'Known' END","Confusing null with zero leads to calculation errors"
Data Entry Typos,df['name'].str.lower().value_counts() looking for similar values,"Use fuzzy matching to identify and merge typos","from fuzzywuzzy import fuzz; identify similar strings","Use pg_trgm or Levenshtein distance functions","Typos split metrics that should be grouped together"
Orphan Records,df.merge(reference_df, how='left', indicator=True).query('_merge == \"left_only\"'),"Remove orphans or add to reference table","df = df[df['foreign_key'].isin(reference_df['id'])]","WHERE foreign_key IN (SELECT id FROM reference_table)","Orphan records indicate referential integrity issues"
Mixed Numeric Formats,df['col'].str.contains(r'[\$,â‚¬%]'),"Extract numeric values removing currency/percent symbols","df['amount'] = df['amount'].str.replace('[$,]', '', regex=True).astype(float)","CAST(REPLACE(REPLACE(col, '$', ''), ',', '') AS DECIMAL)","Mixed formats prevent numeric operations"
Boolean Inconsistency,df['flag'].unique() showing mixed True/False/1/0/Yes/No,"Standardize to consistent boolean representation","df['flag'] = df['flag'].map({'Yes': True, 'No': False, 1: True, 0: False})","CASE WHEN flag IN ('Yes', 'Y', '1', 'true') THEN TRUE ELSE FALSE END","Inconsistent booleans cause filtering errors"
Data Freshness,df['updated_at'].max() vs expected freshness,"Alert if data is stale beyond threshold","assert (pd.Timestamp.today() - df['updated_at'].max()).days < 1, 'Data is stale'","WHERE updated_at >= CURRENT_DATE - INTERVAL '1 day'","Stale data leads to incorrect analysis and decisions"
Cardinality Changes,Compare df['col'].nunique() to historical baseline,"Alert if cardinality changes unexpectedly","assert df['category'].nunique() == expected_count, f'Expected {expected_count} categories'","SELECT COUNT(DISTINCT col) and compare to metadata","New or missing categories indicate upstream issues"
Range Violations,df[~df['col'].between(min_val, max_val)],"Flag or remove out-of-range values","df = df[df['age'].between(0, 120)]","WHERE age BETWEEN 0 AND 120","Out-of-range values indicate data quality issues"
